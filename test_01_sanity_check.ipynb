{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140effdb-08aa-4420-81cc-4c8186afe67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6a5c7c-2f95-4df0-b971-a590581bda07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Analysis Summary: The image depicts a hand applying a force \\( F \\) to a wrench. The wrench is shown with a pivot point labeled \\( O \\) and a distance \\( d \\) from the pivot to where the force is applied. The wrench is being rotated around the pivot point \\( O \\) in a circular motion, indicated by the blue arrow around the axis labeled \\( z \\). This setup illustrates the concept of torque, where the force applied at a distance from the pivot causes rotation.\n"
     ]
    }
   ],
   "source": [
    "# Set up OpenAI client with your API key\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Function to serialize image to base64\n",
    "def serialize_image(image_path):\n",
    "    \"\"\"Convert an image to a base64-encoded string.\"\"\"\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        img_bytes = img_file.read()\n",
    "        return base64.b64encode(img_bytes).decode(\"utf-8\")  # Convert bytes to UTF-8 string\n",
    "\n",
    "# Function to send image to OpenAI GPT-4 Turbo with Vision\n",
    "def analyze_image(image_path):\n",
    "    \"\"\"Send base64-encoded image to OpenAI API for vision-based inference.\"\"\"\n",
    "    base64_image = serialize_image(image_path)  # Convert image to base64\n",
    "    try:\n",
    "        client = openai.OpenAI(api_key=openai_api_key)  # Replace with your API key\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # Vision-enabled GPT-4 model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Describe the image content in detail.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=300\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content.strip()  # Extract the AI's response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example Usage\n",
    "image_path = \"ex1.jpg\"  # Path to your image file\n",
    "summary = analyze_image(image_path)\n",
    "print(\"Image Analysis Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a11a4c77-2403-4247-835c-b4afc76ead3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# Your Base64 string\n",
    "base64_image = serialize_image(image_path)\n",
    "\n",
    "# Decode and open image\n",
    "image_data = base64.b64decode(base64_image)\n",
    "image = Image.open(BytesIO(image_data))\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b3d4d1-b390-4038-93cb-966c6137110c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error code: 400 - {'error': {'message': \"Invalid type for 'messages[1].content': expected one of a string or array of objects, but got an object instead.\", 'type': 'invalid_request_error', 'param': 'messages[1].content', 'code': 'invalid_type'}}\n",
      "GPT-4's response: None\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import base64\n",
    "import openai\n",
    "\n",
    "\n",
    "def serialize_object(obj):\n",
    "    \"\"\"Serialize an object using pickle and encode it as a base64 string.\"\"\"\n",
    "    obj_bytes = pickle.dumps(obj)  # Convert object to bytes\n",
    "    return base64.b64encode(obj_bytes).decode('utf-8')  # Encode as base64 string\n",
    "\n",
    "# Function to get summary from OpenAI API\n",
    "def get_summary(text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",  # Use \"gpt-3.5-turbo\" if needed\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"I have a tabular content, plz describe the contents.\"},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example object (could be a dictionary, DataFrame, etc.)\n",
    "my_dict = {\"key1\": \"value1\", \"key2\": \"value2\"}\n",
    "\n",
    "# Step 1: Serialize the object\n",
    "base64_str = serialize_object(my_dict)\n",
    "\n",
    "# Step 2: Send the base64 string to GPT-4 for processing\n",
    "bytes_data = base64.b64decode(base64_str)\n",
    "obj = pickle.loads(bytes_data)\n",
    "gpt_response = get_summary(obj)\n",
    "\n",
    "# Print the response from GPT-4\n",
    "print(\"GPT-4's response:\", gpt_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b947f4e7-e480-4bef-b48f-a700ca9c2e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New PDF saved at ./data/QA/new_chap_1_QA.pdf\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "\n",
    "# Path to your multi-column PDF\n",
    "pdf_path = './data/QA/chap_1_QA.pdf'\n",
    "\n",
    "# Convert PDF to images (one per page)\n",
    "pages = convert_from_path(pdf_path, 300)  # 300 DPI for better accuracy\n",
    "\n",
    "# List to hold new pages (images)\n",
    "new_pages = []\n",
    "\n",
    "# Process each page\n",
    "for page_number, page in enumerate(pages):\n",
    "    width, height = page.size\n",
    "    \n",
    "    # Define the left and right halves of the page (vertically split)\n",
    "    left_half = page.crop((0, 0, width // 2, height))  # Left half\n",
    "    right_half = page.crop((width // 2, 0, width, height))  # Right half\n",
    "    \n",
    "    # Save the left and right halves as separate new images\n",
    "    left_image_path = f\"left_page_{page_number + 1}.png\"\n",
    "    right_image_path = f\"right_page_{page_number + 1}.png\"\n",
    "    \n",
    "    left_half.save(left_image_path)\n",
    "    right_half.save(right_image_path)\n",
    "    \n",
    "    # Append image paths to new_pages (for later inclusion in PDF)\n",
    "    new_pages.append(left_image_path)\n",
    "    new_pages.append(right_image_path)\n",
    "\n",
    "# Create a new PDF with the new images (left and right halves)\n",
    "output_pdf_path = './data/QA/new_chap_1_QA.pdf'\n",
    "c = canvas.Canvas(output_pdf_path, pagesize=letter)\n",
    "\n",
    "for image_path in new_pages:\n",
    "    c.drawImage(image_path, 0, 0, width=400, height=600)  # Adjust the width/height as needed\n",
    "    c.showPage()  # Move to the next page\n",
    "\n",
    "c.save()\n",
    "\n",
    "print(f\"New PDF saved at {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19aeb9-bd1f-4585-a91f-c95bd75e1671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
